# Multimodal-Video-Emotion-Recognition-Pytorch
This repository contains code for training different uni-modal and multi-modal emotion recognition models written in Pytorch. This work was done as an assignment for the Affective Computing course (Spring'20) at IIIT Delhi. The file `Report.pdf` provides more details.

## Final Architectures

### Feature Extraction
![Feature Extraction](https://github.com/vishaal27/Multimodal-Video-Emotion-Recognition-Pytorch/blob/master/images/models/AFC_diag1.png)

### Hybrid Fusion model 
![Hybrid Fusion model](https://github.com/vishaal27/Multimodal-Video-Emotion-Recognition-Pytorch/blob/master/images/models/AFC_diag2.png)

### MTL model
![MTL model](https://github.com/vishaal27/Multimodal-Video-Emotion-Recognition-Pytorch/blob/master/images/models/AFC_diag3.png)

## Results

### Baseline results
![Baseline results](https://github.com/vishaal27/Multimodal-Video-Emotion-Recognition-Pytorch/blob/master/images/results/baseline.png)

### Final results
![Final results](https://github.com/vishaal27/Multimodal-Video-Emotion-Recognition-Pytorch/blob/master/images/results/final.png)
